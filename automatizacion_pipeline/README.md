# Apache Airflow â€“ DAGs Funcionales y AutomatizaciÃ³n de Pipelines

Este repositorio contiene la implementaciÃ³n de **DAGs funcionales en Apache Airflow**, desarrollados como ejercicios prÃ¡cticos para comprender la creaciÃ³n, ejecuciÃ³n y monitoreo de workflows basados en **grafos dirigidos acÃ­clicos (DAGs)**.

El proyecto fue desplegado utilizando **Apache Airflow 2.9.3 sobre Docker en Windows**, siguiendo buenas prÃ¡cticas de configuraciÃ³n, diagnÃ³stico y orquestaciÃ³n de pipelines.

---

## ğŸ“Œ Objetivo del ejercicio

- Instalar y configurar Apache Airflow.
- Crear DAGs con mÃºltiples tareas.
- Definir dependencias simples y complejas entre tareas.
- Ejecutar y monitorear DAGs desde la interfaz web.
- Verificar logs de ejecuciÃ³n.
- Comprender el uso de operadores bÃ¡sicos de Airflow.

---

## ğŸ› ï¸ TecnologÃ­as utilizadas

- **Python 3.12**
- **Apache Airflow 2.9.3**
- **Docker & Docker Compose**
- **PostgreSQL 15**
- **Windows 11**

---

## ğŸ“ Estructura del proyecto

```
airflow_docker/
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ saludo_diario.py
â”‚   â”œâ”€â”€ dependencias_complejas.py
â”‚   â”œâ”€â”€ operadores_sensores.py
â”‚   â”œâ”€â”€ operadores_sensores.png
â”‚   â””â”€â”€ README.md
â””â”€â”€ docker-compose.yml
```

---

## ğŸš€ DAG 1: Saludo Diario

### DescripciÃ³n

DAG introductorio que permite validar la correcta instalaciÃ³n y funcionamiento de Apache Airflow.

- **DAG ID**: `saludo_diario`
- **Schedule**: `@daily`
- **Catchup**: deshabilitado

### Flujo de ejecuciÃ³n

```
tarea_bash â†’ tarea_python â†’ tarea_esperar
```

### Resultado esperado

- EjecuciÃ³n secuencial de las tareas.
- VisualizaciÃ³n correcta del flujo en Graph View.
- Logs accesibles desde la interfaz web.

---

## ğŸ§© DAG 2: Pipeline de Ventas con Dependencias Complejas

Como parte del ejercicio de automatizaciÃ³n, se implementÃ³ un DAG que modela un **pipeline ETL de ventas**, incorporando ejecuciÃ³n paralela y sincronizaciÃ³n explÃ­cita entre tareas.

- **DAG ID**: `pipeline_ventas_complejo`
- **Schedule**: `@daily`
- **Catchup**: deshabilitado

---

### 1ï¸âƒ£ VisualizaciÃ³n del grafo de dependencias

El DAG fue visualizado utilizando **Graph View** en la interfaz web de Apache Airflow, permitiendo verificar visualmente el flujo de ejecuciÃ³n y las dependencias entre tareas.

**Flujo verificado:**

```
preparar_entorno â†’ [extraer_api_ventas, extraer_db_productos]
extraer_api_ventas â†’ validar_datos_api â†’ transformar_ventas â†˜
extraer_db_productos â†’ validar_datos_db â†’ transformar_productos â†˜
                                   join_ventas_productos
                                             â†“
                                    cargar_data_warehouse
                                             â†“
                                   enviar_reporte_ejecucion
```

El grafo confirma ejecuciÃ³n paralela en las etapas de extracciÃ³n y validaciÃ³n, seguida de una sincronizaciÃ³n explÃ­cita en la etapa de *join* antes de la carga final.

---

### 2ï¸âƒ£ Pruebas de ejecuciÃ³n del DAG

Para validar el correcto funcionamiento del pipeline se realizaron los siguientes escenarios:

**Prueba del DAG sin scheduler:**
```bash
airflow dags test pipeline_ventas_complejo 2024-01-01
```

**EjecuciÃ³n manual del DAG:**
```bash
airflow dags trigger pipeline_ventas_complejo
```

**RevisiÃ³n de logs de la tarea final:**
```bash
airflow tasks logs pipeline_ventas_complejo enviar_reporte_ejecucion 2024-01-01
```

Los logs confirman que el pipeline se ejecuta correctamente hasta la generaciÃ³n del reporte final.

---

### 3ï¸âƒ£ VerificaciÃ³n conceptual

**a) ElecciÃ³n entre PythonOperator y BashOperator**

El `PythonOperator` se utiliza cuando la tarea requiere lÃ³gica de negocio, procesamiento de datos o validaciones mediante cÃ³digo Python.  
El `BashOperator` es mÃ¡s adecuado para ejecutar comandos del sistema operativo o tareas simples de preparaciÃ³n del entorno, como la creaciÃ³n de directorios o ejecuciÃ³n de scripts shell.

**b) Ventajas de definir dependencias explÃ­citas**

Definir dependencias explÃ­citas permite ejecutar tareas en paralelo, representar claramente el flujo mediante un grafo acÃ­clico, evitar ejecuciones incorrectas y facilitar el monitoreo, debugging y mantenimiento del pipeline.

---

## âœ… Resultados

- DAGs cargados correctamente sin errores.
- Ejecuciones exitosas de todas las tareas.
- Dependencias simples y complejas correctamente definidas.
- VisualizaciÃ³n y monitoreo desde Airflow Web UI.
- Logs accesibles para validaciÃ³n de ejecuciÃ³n.

---

## ğŸ§  Conclusiones

El desarrollo de estos DAGs permitiÃ³ consolidar los conceptos fundamentales de Apache Airflow, incluyendo la definiciÃ³n de workflows, uso de operadores, paralelismo, dependencias complejas y monitoreo de ejecuciones en un entorno Docker.

---
## ğŸ“‚ DAG 3: Pipeline con Sensores y Operador Personalizado

Este DAG incorpora **sensores y operadores personalizados**, simulando un escenario real de ingesta de datos dependiente de eventos externos.

- **DAG ID**: `pipeline_con_sensores_y_operador_custom`
- **Schedule**: `@hourly` (ejecutado manualmente durante pruebas)
- **Catchup**: deshabilitado

### Flujo del DAG
```
esperar_archivo_datos
        â†“
validar_datos_ventas
        â†“
procesar_datos_ventas
        â†“
generar_reporte
        â†“
limpiar_archivos
```

---

## ğŸ§  VerificaciÃ³n conceptual

**Â¿CuÃ¡ndo usar sensores?**  
Se utilizan sensores cuando la ejecuciÃ³n de un pipeline depende de una condiciÃ³n externa, como la llegada de archivos o la disponibilidad de datos.

**Â¿Ventajas de operadores personalizados?**  
Permiten encapsular lÃ³gica de negocio especÃ­fica, mejorar la reutilizaciÃ³n de cÃ³digo y mantener DAGs mÃ¡s limpios.
## ğŸ“Œ Autor

**FabiÃ¡n DÃ­az**  
Proyecto de aprendizaje en Ciencia de Datos / Data Engineering.
