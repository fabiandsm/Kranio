# üèó Arquitectura del Pipeline ETL

## Visi√≥n General

El pipeline ETL procesa datos de e-commerce para generar insights de negocio utilizados por dashboards y reportes anal√≠ticos.

El flujo transforma datos crudos provenientes de m√∫ltiples fuentes en informaci√≥n confiable y estructurada para an√°lisis.

---

## Componentes Principales

### 1. Extracci√≥n (Extract)

**Prop√≥sito:** Obtener datos desde m√∫ltiples fuentes externas.

**Tecnolog√≠as utilizadas:**
- SQLAlchemy
- Requests
- PyArrow

**Fuentes de datos:**
- API REST de plataforma e-commerce
- Base de datos transaccional PostgreSQL
- Archivos CSV de proveedores externos

**Caracter√≠sticas:**
- Extracci√≥n incremental para optimizar rendimiento
- Reintentos autom√°ticos ante fallos
- Validaci√≥n b√°sica de integridad de datos

---

### 2. Transformaci√≥n (Transform)

**Prop√≥sito:** Limpiar, validar y enriquecer datos antes de su almacenamiento.

**Operaciones principales:**
- Limpieza de valores faltantes y outliers
- Normalizaci√≥n de formatos
- C√°lculo de m√©tricas derivadas (ventas, margen, etc.)
- Validaci√≥n de reglas de negocio

---

### 3. Carga (Load)

**Prop√≥sito:** Almacenar datos procesados para su consumo anal√≠tico.

**Destinos:**
- Data Warehouse en PostgreSQL con modelo dimensional
- Data Lake en almacenamiento S3 particionado
- Cache Redis para dashboards de alta velocidad

---

## Flujo de Datos

API E-commerce ‚Üí Validaci√≥n ‚Üí Limpieza ‚Üí Enriquecimiento ‚Üí DW
‚Üì ‚Üì ‚Üì ‚Üì ‚Üì
PostgreSQL DB ‚Üí Normalizaci√≥n ‚Üí Reglas ‚Üí Agregaciones ‚Üí S3